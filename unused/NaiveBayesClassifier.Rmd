---
title: "Naïve Bayes Classifier"
output:
  html_document: default
  html_notebook: default
---
```{r, message=FALSE, warning=FALSE, include=FALSE}
setwd('/Users/renero/Documents/IE/IE 2019/IE 2019 O1/Lessons/6.Naive Bayes/')
#install.packages("kableExtra")

# For dev version
# install.packages("devtools")
devtools::install_github("haozhu233/kableExtra")
library(caret)
library(e1071)
library(tm)
library(varhandle)
library(stringr)
```

Welcome to the first application of Probabilistic classification with Naïve Bayes!

<html>
<img src="https://www.sketchappsources.com/resources/source-image/twitterlogo_1x.png" width="20%">
</html>

In this example we will use **Twitter** as our data source to filter those tweets that are talking about a given application. This is a typical problem in probabilistic classification, where I'll use a large sample of texts corresponding to the category that I want to recognize, and another large sample of texts unrelated to that category. That way, by exploring the different word frequencies and probabilities, we'll determine if a new text belongs to one or another category, by simply looking at the existing evidence.

### Problem Statement

There is a real app called "Mandrill"

<html>
<img src="https://pbs.twimg.com/profile_images/604326524976680960/V0gyyhdH.png" width="15%"><P>
</html>

And I want to scan twitter to capture only those tweets that mention my APP. But I don't want to read tweets talking about the animal (the actual mandrill), so I need a classifier for the tweets, that will **filter** only those which are relevant.

For this part of the problem part of the data preparation job is already done, so you start with a few hundreds tweets captured using Tiwtter API, with the word **Mandrill** in them. The file with tweets (`appWords.txt`) refering to the app looks like this:

    @ericcandino they're unfortunately not for sale but drop us a line via http://help.mandrill.com  a
    @gidogeek you can see what we've been working on and get a general idea of our plans at http://blo
    @guillaumepotier there are several reasons emails go to spam mind submitting a request at http://h
    @icntmx yep  we'd be glad to would you mind submitting a request at http://help.mandrill.com
    @jeremyweir if you submit a request at http://help.mandrill.com   we'll get back to you with some
    @josscrowcroft mind submitting a request via http://help.mandrill.com  with some additional detail

And the file with tweets (`otherWords.txt`) not talking about the app look like this:

    anyway  yeah  that's a thing that's going on  reincarnated mandrill-men
    arin did the spark mandrill trick i was wondering if he would :')
    audio mandrill - happy beat this is a funk song by a band who liked to w
    cannot believe i am the only one in a @mandrill 2012 #tweetfleet t-shirt
    chill penguin and spark mandrill down #megamanx
    cuando pase el bafici y se hayan perdido mandrill  mirageman  mujer metr
    de los creadores de #kiltro #mirageman y #mandrill ahora atacan con #trá

I trimmed lines for better representation, but they're arbitrarily long (within twitter limits).

As you might probably have realized, this is a **supervised problem**, and the _labeling_ of the training data has been already done, by manually separating the tweets among the two possible sets. That is the most boring part, and you always need to do so to train any classifier.

## Data Preparation

What I did to prepare the problem is to process the tweets to convert _raw_ two data files with the frequency count for each individual word on them. So, from `appWords.txt`, I generated `appFreqs.csv`, which summary is like:

```{r, echo=FALSE}
appFile <- read.csv("appFreqs.csv", header=F)
otherFile <- read.csv("otherFreqs.csv", header=F)
appTotal <- sum(appFile$V2)
otherTotal <- sum(otherFile$V2)
appFreqs <- cbind(appFile, freq=log((appFile$V2/appTotal)))
otherFreqs <- cbind(otherFile, freq=log((otherFile$V2/otherTotal)))
```

```{r,echo=F,results='asis',error=F,warning=F}
library(knitr)
library(kableExtra)
options(knitr.table.format = "html") 
kable(head(appFreqs[,1:3]), format = "html") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

And for the tweets about anything **but** the app, the result file `otherFreqs.csv` looks like this:

```{r,echo=F,results='asis',error=F,warning=F}
options(knitr.table.format = "html") 
kable(head(otherFreqs[,1:3]), format = "html") %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

What I did is simply counting the number of occurrences of each word (`V1`) and put that in the column variable `V2`, but I also computed the $log$ of the probability. Remeber the we can use the actual probability as:

$$ P(word) = \frac{count(word)}{\sum_{i=1}^{N}count(word_{i})} $$
or the $log(P)$, as it is more convenient to use those values than the tiny ones that the probability produces. Remeber that when using $logs$ we must sum them, instead of multiplying them. So, what we have in the variable `freq` is:

$$ freq = - log \left( \frac{count(word)}{\sum_{i=1}^{N}count(word_{i})} \right)  $$

## Code

To read the CSV files with the frequencies and compute the $log$ mentioned above, I used this snippet of code 

```{r, eval=FALSE, include=TRUE}
appFile <- read.csv("appFreqs.csv", header=F)
otherFile <- read.csv("otherFreqs.csv", header=F)
```

I need to clean up the words a bit to perform a clean classification over english relevant words, removing numbers, puntuation signs and stopwords. This is a function to remove punctiation signs in the words.

```{r}
# Load stopwords from library into global vars.
my_stopwords = data.frame(stopwords("en"))
colnames(my_stopwords) <- c("english")

cleanup <- function(df) {
  # Remove punctuation signs
  df$V1 <- gsub('[[:punct:] ]+','', df$V1)

  # remove rows matching stopwords
  df <- df[!df$V1 %in% my_stopwords$english, ]

  # Select only those entries which V1 column does not start by character '@'
  df <- df[ which( !grepl("^@", df$V1)), ]

  # Remove also numbers
  df <- df[which(!check.numeric(df$V1)), ]

  # Finally, remove entries with empty words after cleanup
  df <- df[!(is.na(df$V1) | df$V1==""), ]

  # This is just to reset index.
  rownames(df) <- NULL
  df
}
```

Finally, compute what is the total number of words, to calculater what is the freequency of each one. The `appFreqs` dataframe will be the one used to perform naïve Bayes classification.

```{r}
appWords <- cleanup(appFile)
otherWords <- cleanup(otherFile)

# The total number of words on each set.
appTotal <- sum(appWords$V2)
otherTotal <- sum(otherWords$V2)

# Create a new column to hold the word frequency.
appFreqs <- cbind(appWords, freq=log((appWords$V2/appTotal)))
otherFreqs <- cbind(otherWords, freq=log((otherWords$V2/otherTotal)))
```


## A glimpse to the data

We will not need feature engineering, except for all the data preparation mentioned earlier. Nevertheless, let's take a look at the frequencies obtained for the different sets in the variable `V2`:

```{r, echo=FALSE}
density.app = density(appFreqs$V2, bw=10)
density.other = density(otherFreqs$V2, bw=10)
plot(density.other, xlim=c(0,200), main="Density plots for words frequency in app-related tweets (blue)\n and non-app related tweets (red)"); polygon(density.other, col=rgb(1,0,0,0.35), border="red")
lines(density.app, xlim=c(0,200)); polygon(density.app, col=rgb(0,0,1,0.35), border="blue")
```

As you can see the words frequencies obtained for the two sets are quite similar. This doesn't mean that it will be impossible to differentiate one class from the other. This simply means that the frequencies in both sets correspond to a similar communication pattern (tweets in english, mostly). Actually, I cutted the $X$ axis at 200 but the're around 3000 different words on each set, but the frequencies of the long-tail part are really small.

To classify between the two possibilities, we need to look at the words present in the new tweets, and see where are more frequent among the two distributions. Let's go for it.

### Helper functions

I need a function gives me a word frequency in any of the data frames that I used for the two classes.

```{r}
freq  <- function(word, frame) {
  val <- frame[which(frame$V1 == word),]$freq  
  if(length(val) == 0) -1/log(sum(frame$V2))
  else -val
}
```

## The Bayesian classifier. 

Let's build the classifier. I'm using a test set with a few tweets (`test.csv`), and the goal is to read them and say if they are about the app or not. The test set is already labeled with the class each belongs to in the first column. We will luse that information to check if our prediction is OK.

I need a function that will clean up the tweet string, following the same procedure as with the frequecies data frame
```{r}
cleanup_string <- function(string) {
  # Remove punctuation signs
  string <- gsub('[[:punct:] ]+',' ', string)
  string <- removeWords(string, my_stopwords$english)
  string <- str_squish(string)
  string <- gsub(' [[:digit:]]+ ', ' ', string)
  string
}
```

Now, let's loop through the file to compute the MAP (maximum A Posteriori prob.) and thus, determine which class the tweet belongs to:

```{r}
# Read a test file, with the category label in V1 and the tweet contents in V2.
test <- read.csv("test.csv", header=F)            # Read the file with the tweets I'm gonna use for testing.
pred <- character(nrow(test))                     # Allocate a prediction vector

# Loop the rows in the test file.
for(j in 1:nrow(test)) 
{
  tweet <- as.character(test[j, 2])                # Extract the content of the tweet
  tweet <- cleanup_string(tweet)                   # Cleanup the string of the tweet
  wordsInThisTweet <- strsplit(tweet, " ")[[1]]    # Extract the words into a list.
  appProb = as.double(0.0)                         # Initialize the counter of freqs on app set.
  otherProb = as.double(0.0)                       # Initialize the counter of freqs on other set.

  # For every word in this tweet, sum its frequency value.
  for(word in wordsInThisTweet) {
    appProb   <- sum(appProb,   freq(as.character(word), appFreqs))
    otherProb <- sum(otherProb, freq(as.character(word), otherFreqs))
  }
  
  # Categorize according to the score obtained from every subset (App tweets, and Other tweets)
  pred[j] = ifelse(appProb > otherProb, "APP", "OTHER")

  cat(sprintf("%7.3f  %6.3f  [%s] - %s\n",
              appProb, otherProb, 
              ifelse(pred[j] == test[j, "V1"], "✓", "✕"),
              tweet))
}
```

Now print the Confusion Matrix:

```{r, echo=FALSE}
# Place the prediction vector inside the test data frame
test <- cbind(test, pred=pred)
cm <- confusionMatrix(test$pred, test$V1)
print(cm$table)
```

An amazing `r cm$overall[[1]]` accuracy in classifiying tweets!




